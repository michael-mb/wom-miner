{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandlung Ground Truth in CSV\n",
    "import re\n",
    "import pandas as pd\n",
    "# RUB\n",
    "temp = pd.read_json(\"../../../data_mining/ground_truth/RUB_persons.json\", encoding=\"utf-8\")\n",
    "temp.sort_values(by=[\"name\"]).to_csv(\"../results/ground_truth_rub.csv\", index=False, header=False, doublequote=True, sep=\";\")\n",
    "# UDE\n",
    "temp = pd.read_csv(\"../results/ground_truth.csv\", encoding=\"utf-8\", header=None, skiprows=1)\n",
    "temp.columns = [\"id\", \"name\", \"email\", \"homepage\", \"organisation\", \"position\"]\n",
    "temp.sort_values(by=[\"name\"]).to_csv(\"../results/ground_truth_ude.csv\", index=False, header=False, doublequote=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDE\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# Import the \"mining\" root folder\n",
    "import os, sys\n",
    "parent_dir = os.path.abspath(\"../..\")\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "truth = pd.read_csv(\"../results/ground_truth.csv\", encoding=\"utf-8\", index_col=False, header=None, skiprows=1)  # found by naive person search by URL\n",
    "truth.columns = [\"id\", \"name\", \"email\", \"homepage\", \"organisation\", \"position\"]\n",
    "found = pd.read_csv(\"../results/people-ude.csv\", encoding=\"utf-8\", index_col=False, header=None, skiprows=1)    # found by the people miner\n",
    "found.columns = [\"title\", \"name\", \"email\", \"method\", \"homepage\", \"foundIn\"]\n",
    "\n",
    "uni = \"ude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUB\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# Import the \"mining\" root folder\n",
    "import os, sys\n",
    "parent_dir = os.path.abspath(\"../..\")\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "truth = pd.read_json(\"../../../data_mining/ground_truth/RUB_persons.json\", encoding=\"utf-8\")  # found by naive person search by URL\n",
    "# truth.columns = [\"id\", \"name\", \"email\", \"homepage\", \"organisation\", \"position\"]\n",
    "found = pd.read_csv(\"../results/people-rub.csv\", encoding=\"utf-8\", index_col=False, header=None, skiprows=1)    # found by the people miner\n",
    "found.columns = [\"title\", \"name\", \"email\", \"method\", \"homepage\", \"foundIn\"]\n",
    "\n",
    "uni = \"rub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = truth.duplicated(subset=[\"name\"], keep=False)\n",
    "# truth[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write duplicates in Ground Truth to a file - UDE\n",
    "with open(f\"result_{uni}_duplicates.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Duplicates found in Ground Truth data\\n# Generated by evaluation.ipynb\")\n",
    "    for index, row in truth[duplicates].sort_values(by=[\"name\"]).iterrows():\n",
    "        f.write(f\"https://www.uni-due.de/person/{row['id']:<6}\\t{row['name']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write duplicates in Ground Truth to a file - RUB\n",
    "with open(f\"result_{uni}_duplicates.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Duplicates found in Ground Truth data\\n# Generated by evaluation.ipynb\")\n",
    "    for index, row in truth[duplicates].sort_values(by=[\"name\"]).iterrows():\n",
    "        f.write(f\"{row['name']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from people.name_analysis import full_title_group, is_normalized_name\n",
    "\n",
    "# 1. Remove academic grades from truth\n",
    "truth[\"title\"] = truth[\"name\"].apply(lambda n: re.search(full_title_group + r\"|()\", n).group())\n",
    "truth[\"name\"] = truth.apply(lambda x: x[\"name\"].replace(x[\"title\"], \"\").strip().strip(\",\").strip(), axis=1)\n",
    "\n",
    "# 2. Remove wrong names\n",
    "truth = truth[truth[\"name\"].apply(is_normalized_name)]\n",
    "truth = truth.drop_duplicates(subset=[\"name\"])\n",
    "found = found.drop_duplicates(subset=[\"name\"])\n",
    "\n",
    "# 3. Filter \"Wissenschaftliche Mitarbeiter\" and people with academic titles\n",
    "# (see next snippet)\n",
    "# truth = truth.loc[truth[\"name\"].empty]\n",
    "# truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate, SEPARATING_LINE\n",
    "\n",
    "# Utils\n",
    "def eval(name, filter, base):\n",
    "    \"\"\"Returns a tuple with the count of filter and the percentage of filter in base\"\"\"\n",
    "    return (name, len(filter.index), (len(filter.index)/len(base.index))*100)\n",
    "\n",
    "data = [\n",
    "    (\"Truth total\", len(truth.index), 100),\n",
    "    (\"Found total\", len(found.index), 100),\n",
    "    SEPARATING_LINE\n",
    "]\n",
    "\n",
    "def add_metrics(f, t, name=None):\n",
    "    true_pos = f[f[\"name\"].isin(t[\"name\"])]     # X in found and in truth\n",
    "    false_pos = f[~f[\"name\"].isin(t[\"name\"])]   # X in found but not in truth\n",
    "    false_neg = t[~t[\"name\"].isin(f[\"name\"])]   # X in truth but not in found\n",
    "    precision = eval(\"True positive (Precision)\", true_pos, f)\n",
    "    recall = eval(\"Found (Recall)\", true_pos, t)\n",
    "    if name:\n",
    "        data.append(SEPARATING_LINE)\n",
    "        data.append(eval(name,t, truth))\n",
    "    data.append(precision)   # How many results are correct\n",
    "    data.append(recall)      # How many names were actually found\n",
    "    # if precision[-1] > 0 and recall[-1] > 0: # TODO WHY???\n",
    "    data.append((\"F1\", None, 2*((precision[-1]*recall[-1])/(precision[-1]+recall[-1]))))\n",
    "    data.append(eval(\"Not correct (False positive)\", false_pos, f))\n",
    "    data.append(eval(\"Not found (False negative)\", false_neg, t))\n",
    "\n",
    "# Print metrics\n",
    "\n",
    "add_metrics(found, truth)\n",
    "add_metrics(found, truth[truth[\"title\"].str.len()>0], \"People with title\")\n",
    "if uni == \"ude\":\n",
    "    add_metrics(found, truth[truth[\"email\"].notnull()], \"People with email\")\n",
    "else:\n",
    "    add_metrics(found, truth[truth[\"mail_arbeit\"].notnull() | truth[\"mail_2\"].notnull()], \"People with email\")\n",
    "position_col = 'position' if uni == \"ude\" else \"jobtitel\"\n",
    "add_metrics(found, truth[truth[position_col].str.contains(\"wiss\\.|wissenschaftl\", case=False, na=False)], \"Wiss. MA\")\n",
    "add_metrics(found, truth[truth[position_col].notnull()], \"Mind. 1 position\")\n",
    "add_metrics(found[found['name'].str.startswith((\"A\", \"a\",))], truth[truth['name'].str.startswith((\"A\", \"a\",))], \"Names with A\")\n",
    "\n",
    "found_start_a = found[found['name'].str.startswith((\"A\", \"a\",))]\n",
    "truth_start_a = truth[truth['name'].str.startswith((\"A\", \"a\",))]\n",
    "if uni == \"ude\":\n",
    "    add_metrics(found_start_a, truth_start_a[truth_start_a[\"email\"].notnull()], \"Names with A and email\")\n",
    "else:\n",
    "    add_metrics(found_start_a, truth_start_a[truth_start_a[\"mail_arbeit\"].notnull() | truth_start_a[\"mail_2\"].notnull()], \"Names with A and email\")\n",
    "\n",
    "# add_metrics(found, truth[truth[position_col].str.contains(\"wiss\\.|wissenschaftl\", case=False, na=False) & truth[\"email\"].notnull()], \"Wiss. MA with email\")\n",
    "\n",
    "s = tabulate(data, floatfmt=\",.2f\", headers=(\"Metric\", \"Count\", \"%\"))\n",
    "with open(f\"result_{uni}_metrics.txt\", \"w\") as f:\n",
    "    f.write(s)\n",
    "# print(s)\n",
    "\n",
    "# truth[\"name\"].sort_values().to_csv(f\"result_{uni}_truth.csv\", index=False, header=False, doublequote=False)\n",
    "# found[\"name\"].sort_values().to_csv(f\"result_{uni}_found.csv\", index=False, header=False, doublequote=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth[\"name\"].sort_values().to_csv(f\"result_{uni}_truth.csv\", index=False, header=False, doublequote=False)\n",
    "found[\"name\"].sort_values().to_csv(f\"result_{uni}_found.csv\", index=False, header=False, doublequote=False)\n",
    "truth[~truth[\"name\"].isin(found[\"name\"])].sort_values(by=[\"name\"]).to_csv(f\"result_{uni}_not_found.csv\",     index=False, header=False, doublequote=True, sep=\";\")\n",
    "truth[ truth[\"name\"].isin(found[\"name\"])].sort_values(by=[\"name\"]).to_csv(f\"result_{uni}_truth_found.csv\",   index=False, header=False, doublequote=True, sep=\";\")\n",
    "found[~found[\"name\"].isin(truth[\"name\"])].sort_values(by=[\"name\"]).to_csv(f\"result_{uni}_not_correct.csv\",   index=False, header=False, doublequote=True, sep=\";\")\n",
    "found[ found[\"name\"].isin(truth[\"name\"])].sort_values(by=[\"name\"]).to_csv(f\"result_{uni}_found_correct.csv\", index=False, header=False, doublequote=True, sep=\";\")\n",
    "# truth[~truth[\"name\"].isin(found[\"name\"]) & truth[\"position\"].notnull() & truth[\"email\"].notnull()].sort_values(by=[\"name\"]).to_csv(\"result_not_found_position_and_mail.csv\", index=False, header=False, doublequote=True, sep=\";\")\n",
    "# found[~found[\"name\"].isin(truth[\"name\"]) & truth[\"position\"].notnull() & truth[\"email\"].notnull()].sort_values(by=[\"name\"]).to_csv(\"result_not_correct_position_and_mail.csv\", index=False, header=False, doublequote=True, sep=\";\")\n",
    "\n",
    "# Saves found names starting with A and truth names starting with A and an email to files\n",
    "found[found[\"name\"].str.startswith((\"A\", \"a\",))].sort_values(by=[\"name\"]).to_csv(f\"Auswertung {uni} Found.csv\",  index=False, header=False, doublequote=True, sep=\";\")\n",
    "if uni == \"ude\":\n",
    "    truth[truth[\"name\"].str.startswith((\"A\", \"a\",)) & truth[\"email\"].notnull()].sort_values(by=[\"name\"]).to_csv(f\"Auswertung {uni} Truth.csv\", index=False, header=False, doublequote=True, sep=\";\")\n",
    "else:\n",
    "    truth[truth[\"name\"].str.startswith((\"A\", \"a\",)) & (truth[\"mail_arbeit\"].notnull() | truth[\"mail_2\"].notnull())].sort_values(by=[\"name\"]).to_csv(f\"Auswertung {uni} Truth.csv\", index=False, header=False, doublequote=True, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mining-YhlEI64Q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
